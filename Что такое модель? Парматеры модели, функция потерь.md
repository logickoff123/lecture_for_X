
Что значит обучить модель ?  

Вы можете сказать что у нас есть какой то (код), какой-то черный ящик. Который мы как-то обучаем и .... Ура Ура!!!  У нас есть предсказание какой-то переменной. Но как делается это предсказние? Что же лежит в этом черном ящике? не поятно. 

Давай возьмем, пример. 
Представь, у нас есть температура воздуха (x) и продажи мороженого (y). Мы хотим научиться предсказывать продажи по температуре. Как это можно описать?

Мы занем что 

| температура (x) | продажи (y) |
| :-------------- | :---------: |
| 20              |     40      |
| 25              |     70      |
| 30              |     100     |
| 35              |     140     |
Давайте посмотрим и, самое главное, построим зависимость. Ведь у нас есть готовые данные по двум переменным.

![[picture/Screenshot from 2025-09-19 15-55-35.png]]

Как можно описать эти точки? Мы можем провести линию и таким образом видим, что с ростом температуры продажи растут. Эта линия (прямая в данном случае) и будет функцией.

Функция — это правило, где каждому *x* сопоставляется *y*.

Давайте действительно проведем линию через данные точки, чтобы увидеть зависимость более наглядно.


![[picture/Screenshot from 2025-09-19 16-07-29.png]]

И вот мы с тобой построили функцию. Эта функция описывает нам зависимость продаж от температуры. На данной картинке видим, что функция у нас получилась прямая, но, по факту, она может быть любой: параболой, кривой, да вообще любой, какую вы себе представите, — главное, чтобы функция хорошо описывала точки. В нашем случае прямая отлично это делает, мозг сам рисует нам эту линию по точкам.

Ну, окей, прямую провели, можем уже как будто бы что-то предсказать: что при n-ной температуре продаж будет столько-то. Круто! Но давай с тобой рассмотрим функцию более подробно. В частности, мы все (или не все :) ) знаем, что уравнение прямой выглядит следующим образом:

								$y = kx + b$

`y` — то, что мы предсказываем (продажи), `x` — температура. А что такое `k` и `b`?

Ты скажешь мне, что это коэффициенты, и будешь абсолютно прав. Но как они влияют на нашу функцию? Они могут быть любыми? Они как-то подбираются? Мы ставим их на рандом?

Ну, давай поэкспериментируем. Давай я возьму `k = 1` и `b = 0`.

Уравнение будет: `y = 1 * x + 0`.

А теперь давай подставим сюда наши значения, которые мы знаем. Мы точно знаем, какие у нас есть `x` и какой `y` они должны предсказывать.

Наши данные:

| температура (x) | продажи (y) |
| :-------------- | :---------: |
| 20              |     40      |
| 25              |     70      |
| 30              |     100     |
| 35              |     140     |
Наши данные при уравнении  y = 1*x + 0

| температура (x) | продажи (y) |
| :-------------- | :---------: |
| 20              |     20      |
| 25              |     25      |
| 30              |     30      |
| 35              |     35      |
![[picture/Screenshot from 2025-09-19 16-44-58.png]]

Что-то как-то не очень. Прямая лежит где-то внизу, непонятно где. И как нам предсказать наши `y` по `x`, если прямая даже известные переменные описывает криво :((((.

Давай попробуем взять еще какие-нибудь коэффициенты. Допустим, `k = 10` и `b = 0`.

Уравнение: `y = 10 * x`.
![[picture/Screenshot from 2025-09-19 16-52-03.png]]
Уф, ну как-то не очень :(

Если ты продолжишь эксперименты, ты подберешь хорошие коэффициенты. Но давай с тобой приостановимся.

Мы поняли с тобой, что **модель** — это по сути **функция**. Данная функция описывает нам наши данные, и мы по ней можем предсказать переменную **y**.

А **обучить модель** — это значит подобрать такие коэффициенты к этой функции (в нашем случае **k** и **b**), при которых наша прямая наилучшим образом описывает зависимость в наших данных.

Коэффициенты в машинном обучении называют чаще всего `w₁` и `w₀`.

Ура! Вот мы и с тобой поняли, что такое обучить модель.

Но вопрос: у нас с тобой есть глаза, и мы можем понять, что вот эта прямая — ужасная, а другая — хорошая. Но как это понимает машина? Она не смотрит на график, как мы. Она считает **ошибку**.

Машине нужен чёткий, числовой способ отличить "хорошо" от "плохо". Этот способ — **функция ошибки (или функция потерь)**.

Давай с тобой попробуем формализовать нашу интуицию. Как мы с тобой решили, что те два графика, которые мы построили, плохие?
1. y = 1*x + 0  
		при x=20, `ŷ=20`, а `y=40`. Разница = 20.
2.  y = 10*x`
		при x=20, `ŷ=200`, а `y=40`. Разница = 160

Мы посмотрели на разницу между тем, что **предсказала наша модель** (`ŷ`), и тем, что **произошло на самом деле** (`y`).

**Чем больше эта разница, тем хуже модель. 

--------------------------------------------------------------------
Давай немного отлечемся и дадим этим понятиям точные имена, чтобы нам было проще говорить и чтобы машина нас понимала.

- **`y`** — это то, что мы хотим предсказать. В нашем случае — продажи. Это наша **целевая переменная** (target). Её значения нам известны из исторических данных, и по ним мы учимся.
    
- **`x`** — это то, по чему мы предсказываем. Температура. Это **признак** или **фича** (feature).
    
- **`ŷ`** (игрек с крышечкой) — это **предсказание** модели. То, что она насчитала, основываясь на `x` и своих параметрах.
-----------------------------------------------------------------------
Окей, а теперь давай вернемся к нашей проблеме: как машина понимает, что произошла ошибка? Ну, окей, вот мы с тобой ошибку посчитали, посчитали для одних данных. Посчитаем для другого и для третьего. А если данных 400? Будем для каждой считать ошибку? Если да, то мы с тобой сойдем с ума и ляжем в психушку.

Да и предположим, что посчитали (мы упорные) и для каждого примера данных посчитали ошибку. И что с этими ошибками делать? Складывать? Ну, мы не можем так с тобой сделать. Потому что в одной точке ошибка может быть +50, а в другой -50 (не забывай, что наша функция может быть любой, прямую я взяла в качестве примера). Так вот, если мы с тобой сложим 50 и -50, они дадут нам 0. И таких схлопываний может быть много — модель будет казаться идеальной, а по факту она будет катастрофически плохой.

Нам нужно какое-то умное решение для этой неурядицы.

Но ты можешь сказать: «Окей, складывать ошибки не можем, давай их будем брать по модулю `|y - ŷ|`!». Модуль будет уничтожать наш отрицательный знак, и в целом как будто бы получается здорово и классно. И ты будешь абсолютно прав!

НО теперь вторая проблема. У нас с тобой не 4 переменных, как с мороженым, а 400 или 400 000. И ошибки все разные: где-то 2, где-то 10, а где-то 200.

Как нам одним числом сказать, насколько сильно ошибается модель? Если мы просто сложим их, пусть и по модулю, мы получим огромное число. И это число нам с тобой ни о чём не говорит. Оно будет большим потому, что данных много, или потому, что модель плохая?

Нам с тобой нужен способ, который покажет **среднюю ошибку на один прогноз**.

И это по сути гениальное решение — просто взять эту большую сумму и поделить на количество переменных. И вот мы, по сути, и получили первую функцию ошибки: берем по модулю наши ошибки, складываем их и делим на их же количество.

То, что я написала, называется **MAE**, и формула у нее следующая:

$$
MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|
$$
### Обозначения:
- $n$ — количество наблюдений
- $y_i$ — фактическое значение (ground truth)
- $\hat{y}_i$ — предсказанное значение (prediction)
- $\sum$ — оператор суммирования
- $|\cdot|$ — модуль (абсолютное значение)


**MAE** = **Mean Absolute Error** - Средняя абсолютная ошибка

Окей! С этим разобрались. Давай вернемся к примеру с мороженым.

Вот мы с тобой подбираем параметры `ŷ = w₁ * x + w₀`. Предположим, что мы подобрали две пары параметров, которые вроде бы неплохо работают:

- `w₁ = a, w₀ = b` -> Ошибки: `[10, 10, 10, 10]`
    
- `w₁ = c, w₀ = d` -> Ошибки: `[1, 1, 1, 37]`
    
- **Считаем ошибку для КАЖДОГО набора параметров:** Для этого мы подставляем в нашу модель с конкретными параметрами все `x` из данных, получаем предсказания `ŷ`, сравниваем их с реальными `y` и получаем массив ошибок.
    
- **Сворачиваем ошибки в одно число:** Чтобы сравнить две модели (два набора параметров), мы не можем смотреть на 4 ошибки сразу. Мы используем формулу (например, MAE), чтобы превратить их в одно число — "рейтинг качества" этой конкретной модели с этими конкретными параметрами.
    

Давай посчитаем, чему будет равна ошибка MAE в первом и втором случае.

MAE₁ = (|10| + |10| + |10| + |10|) / 4 = 40 / 4 = 10  
MAE₂ = (|1| + |1| + |1| + |37|) / 4 = 40 / 4 = 10

Средняя абсолютная ошибка одинаковая? Но ведь ошибки, которые мы посчитали, разные! И как понять, какая модель лучше?

К сожалению, MAE скрывает важную деталь — а именно **разброс ошибок**. И исходя из этого, мы можем сделать вывод, что нам нужна другая функция ошибок, которая бы эту разницу учитывала.

Давай подумаем, как можно подсветить то, что у нас есть выбросы. Правильно! Сделать их еще **больше**!

---

Отличный пример, который показывает ограничения MAE! Жду, как вы предложите "увеличить" выбросы.

New chat

Давай возьмем наш пример 

1)`[10, 10, 10, 10]` 
2)`[1, 1, 1, 37]`

И возведем каждую ошибку в **квадрат**
В первом случаи получим 10

1)`[10^2, 10^2, 10^2, 10^2 ]` =  [ 100 , 100, 100, 100] =100 + 100+ 100+100= 400 /4 = 100
2)`[1^2, 1^2, 1^2, 37^2]` = [1,1,1,1369] =1 +1 + 1 + 1369 = 1372/4 = 343

Видим что в первом случаи ошибка меньше чем во втором то что мы сейчас с тобой сдлеали называетсья MSE  - среднеквардратичная ошибка 


$$
MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2
$$

### Обозначения:
- $n$ — количество наблюдений в выборке
- $y_i$ — фактическое значение (ground truth)
- $\hat{y}_i$ — предсказанное значение (prediction)
- $\sum_{i=1}^{n}$ — сумма от первого до последнего элемента
- $( \cdot )^2$ — квадрат разности

**MSE (Mean Squared Error)** — **среднеквадратическая ошибка**














